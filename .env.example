# OpenAI API configuration
OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=o3-mini  # Options: o3-preview, o3-mini, gpt-4-turbo, gpt-3.5-turbo, etc.
OPENAI_ENDPOINT=https://api.openai.com/v1  # Optional: for Azure or other endpoints

# Firecrawl configuration (Search and Web Crawling)
FIRECRAWL_KEY=your_firecrawl_key  # Not needed if using local Firecrawl
# FIRECRAWL_BASE_URL=http://localhost:3002  # Uncomment for local Firecrawl
FIRECRAWL_CONCURRENCY=3  # Number of concurrent requests

# Optional: Langfuse observability
# LANGFUSE_PUBLIC_KEY=your_langfuse_public_key
# LANGFUSE_SECRET_KEY=your_langfuse_secret_key
# LANGFUSE_BASEURL=https://us.cloud.langfuse.com

# Optional: Custom context size for models (in tokens)
# CONTEXT_SIZE=128000

# Debugging configuration
# DEBUG_MODE=true         # Enable debugging
# DEBUG_LEVEL=3           # 1=ERROR, 2=WARN, 3=INFO, 4=DEBUG, 5=TRACE
# DEBUG_PROMPTS=true      # Log all prompts sent to LLMs
# DEBUG_RESPONSES=true    # Log all responses from LLMs
# DEBUG_PROGRESS=true     # Log research progress updates
# DEBUG_SOURCES=true      # Log detailed source information 